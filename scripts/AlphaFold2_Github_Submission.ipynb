{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"200\" align=\"right\" style=\"height:240px\">\n",
        "\n",
        "##ColabFold v1.5.2: AlphaFold2 using MMseqs2\n",
        "\n",
        "Easy to use protein structure and complex prediction using [AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2) and [Alphafold2-multimer](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1). Sequence alignments/templates are generated through [MMseqs2](mmseqs.com) and [HHsearch](https://github.com/soedinglab/hh-suite). For more details, see <a href=\"#Instructions\">bottom</a> of the notebook, checkout the [ColabFold GitHub](https://github.com/sokrypton/ColabFold) and read our manuscript. \n",
        "Old versions: [v1.4](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.4.0/AlphaFold2.ipynb), [v1.5.1](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.1/AlphaFold2.ipynb)\n",
        "\n",
        "[Mirdita M, SchÃ¼tze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
        "*Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13NC3B_j6xOj",
        "outputId": "609da9db-d345-465d-9686-21e96e04de78"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ5DyU8V_qCd"
      },
      "outputs": [],
      "source": [
        "def generate_sequence_from_linker(linker):\n",
        "    #amyloid beta 42 sequence, can change this if another amyloid protein is of interest\n",
        "    abeta_42 = 'DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA'\n",
        "    \n",
        "    #linker sequence\n",
        "    link = linker\n",
        "\n",
        "    #this .pdb reference contains a pentamer of abeta42, therefore there will be 4 linkers and 5 main chain sequences\n",
        "    n_mer = 5\n",
        "\n",
        "    main_chain = ''\n",
        "    for n in range(n_mer-1):\n",
        "        main_chain += abeta_42 + link\n",
        "\n",
        "    main_chain += abeta_42\n",
        "    \n",
        "    return main_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wPUr7nf8duX",
        "outputId": "b7ecb4be-ade0-4ced-80ca-57d80aeb8736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "['DIMIIK', 'DIMVVK', 'DVMIVK', 'GSMLHH', 'DIMLVK', 'DLMIVK', 'HNHMLI', 'SGIGDR', 'TGVGDR', 'HYNIEL', 'GTQRFI', 'KEQKNV', 'GSQRFV', 'NMSMTT', 'NMTMST', 'NMTMTS', 'EFRYEV', 'IASKIS', 'VASKVS', 'IASKVT', 'IATKVS', 'GTMIHH', 'DHMHTS', 'DHMHST', 'KQEHQI', 'HNHMIV', 'RQTVKR', 'RQSIKR', 'SEITNY', 'SEVSNY', 'TEVTNY', 'IVSRYL', 'VISRYL', 'IITRYL', 'HYNVEI', 'HNVRKH', 'KEQKNL', 'YGSMTQ', 'YGTMSQ', 'VFEHSH', 'IFEHTH', 'QERSFE', 'RYIDVA', 'RYVDIA', 'DYIFGY', 'EFRYEL', 'LASKVS', 'IDNFHH', 'HQALLI', 'RQTLKR', 'FYGLIY', 'IISRYI', 'ILSRYL', 'LISRYL', 'IHYRKA', 'ENQMMV', 'HNLRKH', 'REQLEI', 'LFEHSH', 'SLMLIS', 'SLMLVT', 'TLMLVS', 'FSHYHA', 'TAVLAY', 'HQAILV', 'HQALIV', 'SAILAY', 'NKGHSN', 'VETFRQ', 'IESFRQ', 'IHDARS', 'VHDART', 'FYGIVY', 'KIANDY', 'DIMVIK', 'DVMIIK', 'DVMVVK', 'ENQMML', 'ILFMQI', 'VLFMQV', 'DIFIVK', 'REQIEV', 'DIMIVR', 'FIMSMI', 'FVMSMV', 'SIMLVS', 'SLMIVS', 'FVMTMI', 'IIAMFL', 'VVAMFL', 'HQHMLV', 'YIVMRT', 'YVIMRT', 'TAIIAY', 'TALLAY', 'YVVMRS', 'LETFRQ', 'DVMLVK', 'DLMIIK', 'DIMLIK']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "import json\n",
        "\n",
        "from google.colab import files\n",
        "from sys import version_info \n",
        "\n",
        "#set this to true if running random linker file, false otherwise\n",
        "isRandom = False\n",
        "\n",
        "if isRandom:\n",
        "  #TODO: Change the path for the linker file\n",
        "  with open('/content/drive/MyDrive/10C51_Project/second_random_100_linkers.txt') as f:\n",
        "      contents = f.read()\n",
        "\n",
        "  linker_list = [s.replace(\"'\",\"\").replace(\"\\n\", \"\") for s in contents.strip(\"[]\").split(\" \")]\n",
        "\n",
        "# Reading in the jsonl file (result from active learning loop)\n",
        "# Need to be moved from local to drive \n",
        "else: \n",
        "  #TODO: Change the path for the linker file\n",
        "  with open('/content/drive/MyDrive/10C51_Project/active_learning_results/UCB/loop_0.jsonl') as f:\n",
        "    line = f.readline()\n",
        "    data = json.loads(line.strip())\n",
        "  linker_list = list(data.keys())\n",
        "\n",
        "# double-check the linker list\n",
        "print(len(linker_list))\n",
        "print(linker_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOblAo-xetgx",
        "outputId": "972f99af-249b-4150-fcec-94a237c89324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "jobname test_a5e17\n",
            "sequence PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK\n",
            "length 59\n"
          ]
        }
      ],
      "source": [
        "#@title Input protein sequence(s), then hit `Runtime` -> `Run all`\n",
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "\n",
        "from sys import version_info \n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "\n",
        "def add_hash(x,y):\n",
        "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
        "\n",
        "\n",
        "\n",
        "query_sequence = 'PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK' #@param {type:\"string\"}\n",
        "#@markdown  - Use `:` to specify inter-protein chainbreaks for **modeling complexes** (supports homo- and hetro-oligomers). For example **PI...SK:PI...SK** for a homodimer\n",
        "jobname = 'test' #@param {type:\"string\"}\n",
        "# number of models to use\n",
        "num_relax = 0 #@param [0, 1, 5] {type:\"raw\"}\n",
        "#@markdown - specify how many of the top ranked structures to relax using amber\n",
        "template_mode = \"none\" #@param [\"none\", \"pdb70\",\"custom\"]\n",
        "#@markdown - `none` = no template information is used. `pdb70` = detect templates in pdb70. `custom` - upload and search own templates (PDB or mmCIF format, see [notes below](#custom_templates))\n",
        "\n",
        "use_amber = num_relax > 0\n",
        "\n",
        "# remove whitespaces\n",
        "query_sequence = \"\".join(query_sequence.split())\n",
        "\n",
        "basejobname = \"\".join(jobname.split())\n",
        "basejobname = re.sub(r'\\W+', '', basejobname)\n",
        "jobname = add_hash(basejobname, query_sequence)\n",
        "\n",
        "# check if directory with jobname exists\n",
        "def check(folder):\n",
        "  if os.path.exists(folder):\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "if not check(jobname):\n",
        "  n = 0\n",
        "  while not check(f\"{jobname}_{n}\"): n += 1\n",
        "  jobname = f\"{jobname}_{n}\"\n",
        "\n",
        "# make directory to save results\n",
        "os.makedirs(jobname, exist_ok=True)\n",
        "\n",
        "# save queries\n",
        "queries_path = os.path.join(jobname, f\"{jobname}.csv\")\n",
        "with open(queries_path, \"w\") as text_file:\n",
        "  text_file.write(f\"id,sequence\\n{jobname},{query_sequence}\")\n",
        "\n",
        "if template_mode == \"pdb70\":\n",
        "  use_templates = True\n",
        "  custom_template_path = None\n",
        "elif template_mode == \"custom\":\n",
        "  custom_template_path = os.path.join(jobname,f\"template\")\n",
        "  os.makedirs(custom_template_path, exist_ok=True)\n",
        "  uploaded = files.upload()\n",
        "  use_templates = True\n",
        "  for fn in uploaded.keys():\n",
        "    os.rename(fn,os.path.join(custom_template_path,fn))\n",
        "else:\n",
        "  custom_template_path = None\n",
        "  use_templates = False\n",
        "\n",
        "print(\"jobname\",jobname)\n",
        "print(\"sequence\",query_sequence)\n",
        "print(\"length\",len(query_sequence.replace(\":\",\"\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iccGdbe_Pmt9",
        "outputId": "01ef5468-ecd5-4225-dcd7-100bb3e9d439",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "%%bash -s $use_amber $use_templates $python_version\n",
        "\n",
        "set -e\n",
        "\n",
        "USE_AMBER=$1\n",
        "USE_TEMPLATES=$2\n",
        "PYTHON_VERSION=$3\n",
        "\n",
        "if [ ! -f COLABFOLD_READY ]; then\n",
        "  echo \"installing colabfold...\"\n",
        "  # install dependencies\n",
        "  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\n",
        "  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\" \"tensorflow-cpu==2.11.0\"\n",
        "  pip uninstall -yq jax jaxlib\n",
        "  pip install -q \"jax[cuda]==0.3.25\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "\n",
        "\n",
        "  # for debugging\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\n",
        "  touch COLABFOLD_READY\n",
        "fi\n",
        "\n",
        "# setup conda\n",
        "if [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
        "  if [ ! -f CONDA_READY ]; then\n",
        "    echo \"installing conda...\"\n",
        "    wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
        "    rm Miniconda3-latest-Linux-x86_64.sh\n",
        "    conda config --set auto_update_conda false\n",
        "    touch CONDA_READY\n",
        "  fi\n",
        "fi\n",
        "# setup template search\n",
        "if [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\n",
        "  echo \"installing hhsuite...\"\n",
        "  conda install -y -q -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python=\"${PYTHON_VERSION}\" 2>&1 1>/dev/null\n",
        "  touch HH_READY\n",
        "fi\n",
        "# setup openmm for amber refinement\n",
        "if [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\n",
        "  echo \"installing amber...\"\n",
        "  conda install -y -q -c conda-forge openmm=7.5.1 python=\"${PYTHON_VERSION}\" pdbfixer cryptography==38.0.4 2>&1 1>/dev/null\n",
        "  touch AMBER_READY\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2_sh2uAonJH"
      },
      "outputs": [],
      "source": [
        "msa_mode = \"mmseqs2_uniref_env\"\n",
        "pair_mode = \"unpaired_paired\"\n",
        "\n",
        "# decide which a3m to use\n",
        "if \"mmseqs2\" in msa_mode:\n",
        "  a3m_file = os.path.join(jobname,f\"{jobname}.a3m\")\n",
        "\n",
        "elif msa_mode == \"custom\":\n",
        "  a3m_file = os.path.join(jobname,f\"{jobname}.custom.a3m\")\n",
        "  if not os.path.isfile(a3m_file):\n",
        "    custom_msa_dict = files.upload()\n",
        "    custom_msa = list(custom_msa_dict.keys())[0]\n",
        "    header = 0\n",
        "    import fileinput\n",
        "    for line in fileinput.FileInput(custom_msa,inplace=1):\n",
        "      if line.startswith(\">\"):\n",
        "         header = header + 1\n",
        "      if not line.rstrip():\n",
        "        continue\n",
        "      if line.startswith(\">\") == False and header == 1:\n",
        "         query_sequence = line.rstrip()\n",
        "      print(line, end='')\n",
        "\n",
        "    os.rename(custom_msa, a3m_file)\n",
        "    queries_path=a3m_file\n",
        "    print(f\"moving {custom_msa} to {a3m_file}\")\n",
        "    \n",
        "else:\n",
        "  a3m_file = os.path.join(jobname,f\"{jobname}.single_sequence.a3m\")\n",
        "  with open(a3m_file, \"w\") as text_file:\n",
        "    text_file.write(\">1\\n%s\" % query_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADDuaolKmjGW",
        "outputId": "c630687a-2720-4044-cacb-179dc7b34e94"
      },
      "outputs": [],
      "source": [
        "model_type = \"auto\"\n",
        "num_recycles = \"auto\"\n",
        "recycle_early_stop_tolerance = \"auto\"\n",
        "max_msa = \"auto\"\n",
        "num_seeds = 1\n",
        "use_dropout = False\n",
        "\n",
        "num_recycles = None if num_recycles == \"auto\" else int(num_recycles)\n",
        "recycle_early_stop_tolerance = None if recycle_early_stop_tolerance == \"auto\" else float(recycle_early_stop_tolerance)\n",
        "if max_msa == \"auto\": max_msa = None\n",
        "\n",
        "save_all = False\n",
        "save_recycles = False\n",
        "save_to_google_drive = False\n",
        "dpi = 200\n",
        "\n",
        "\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "print(\"You are logged into Google Drive and are good to go!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbaIO9pWjaN0"
      },
      "outputs": [],
      "source": [
        "#@title Run Prediction\n",
        "display_images = True #@param {type:\"boolean\"}\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from Bio import BiopythonDeprecationWarning\n",
        "warnings.simplefilter(action='ignore', category=BiopythonDeprecationWarning)\n",
        "from pathlib import Path\n",
        "from colabfold.download import download_alphafold_params, default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "from colabfold.batch import get_queries, run, set_model_type\n",
        "from colabfold.plot import plot_msa_v2\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "try:\n",
        "  K80_chk = os.popen('nvidia-smi | grep \"Tesla K80\" | wc -l').read()\n",
        "except:\n",
        "  K80_chk = \"0\"\n",
        "  pass\n",
        "if \"1\" in K80_chk:\n",
        "  print(\"WARNING: found GPU Tesla K80: limited to total length < 1000\")\n",
        "  if \"TF_FORCE_UNIFIED_MEMORY\" in os.environ:\n",
        "    del os.environ[\"TF_FORCE_UNIFIED_MEMORY\"]\n",
        "  if \"XLA_PYTHON_CLIENT_MEM_FRACTION\" in os.environ:\n",
        "    del os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]\n",
        "\n",
        "from colabfold.colabfold import plot_protein\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For some reason we need that to get pdbfixer to import\n",
        "if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "def input_features_callback(input_features):  \n",
        "  if display_images:    \n",
        "    plot_msa_v2(input_features)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def prediction_callback(protein_obj, length,\n",
        "                        prediction_result, input_features, mode):\n",
        "  model_name, relaxed = mode\n",
        "  if not relaxed:\n",
        "    if display_images:\n",
        "      fig = plot_protein(protein_obj, Ls=length, dpi=150)\n",
        "      plt.show()\n",
        "      plt.close()\n",
        "\n",
        "\n",
        "#@title Input protein sequence(s), then hit `Runtime` -> `Run all`\n",
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "\n",
        "from sys import version_info \n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "\n",
        "def add_hash(x,y):\n",
        "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jgj8C-oKCsoI",
        "outputId": "543fe5c8-c72b-43cf-a0b5-68ecf757bb43"
      },
      "outputs": [],
      "source": [
        "for i, linker in enumerate(linker_list):\n",
        "  \n",
        "  query_sequence = generate_sequence_from_linker(linker)\n",
        "  jobname = linker\n",
        "  # number of models to use\n",
        "  num_relax = 0\n",
        "  template_mode = \"none\" \n",
        "  use_amber = num_relax > 0\n",
        "\n",
        "  # remove whitespaces\n",
        "  query_sequence = \"\".join(query_sequence.split())\n",
        "  basejobname = \"\".join(jobname.split())\n",
        "  basejobname = re.sub(r'\\W+', '', basejobname)\n",
        "  jobname = add_hash(basejobname, query_sequence)\n",
        "\n",
        "  # check if directory with jobname exists\n",
        "  def check(folder):\n",
        "    if os.path.exists(folder):\n",
        "      return False\n",
        "    else:\n",
        "      return True\n",
        "  if not check(jobname):\n",
        "    n = 0\n",
        "    while not check(f\"{jobname}_{n}\"): n += 1\n",
        "    jobname = f\"{jobname}_{n}\"\n",
        "\n",
        "  # make directory to save results\n",
        "  os.makedirs(jobname, exist_ok=True)\n",
        "\n",
        "  # save queries\n",
        "  queries_path = os.path.join(jobname, f\"{jobname}.csv\")\n",
        "  with open(queries_path, \"w\") as text_file:\n",
        "    text_file.write(f\"id,sequence\\n{jobname},{query_sequence}\")\n",
        "\n",
        "  if template_mode == \"pdb70\":\n",
        "    use_templates = True\n",
        "    custom_template_path = None\n",
        "  elif template_mode == \"custom\":\n",
        "    custom_template_path = os.path.join(jobname,f\"template\")\n",
        "    os.makedirs(custom_template_path, exist_ok=True)\n",
        "    uploaded = files.upload()\n",
        "    use_templates = True\n",
        "    for fn in uploaded.keys():\n",
        "      os.rename(fn,os.path.join(custom_template_path,fn))\n",
        "  else:\n",
        "    custom_template_path = None\n",
        "    use_templates = False\n",
        "\n",
        "  print(\"jobname\",jobname)\n",
        "  print(\"sequence\",query_sequence)\n",
        "  print(\"length\",len(query_sequence.replace(\":\",\"\")))\n",
        "\n",
        "  result_dir = jobname\n",
        "  if 'logging_setup' not in globals():\n",
        "      setup_logging(Path(os.path.join(jobname,\"log.txt\")))\n",
        "      logging_setup = True\n",
        "\n",
        "  queries, is_complex = get_queries(queries_path)\n",
        "  model_type = set_model_type(is_complex, model_type)\n",
        "\n",
        "  if \"multimer\" in model_type and max_msa is not None:\n",
        "    use_cluster_profile = False\n",
        "  else:\n",
        "    use_cluster_profile = True\n",
        "\n",
        "  download_alphafold_params(model_type, Path(\".\"))\n",
        "  results = run(\n",
        "      queries=queries,\n",
        "      result_dir=result_dir,\n",
        "      use_templates=use_templates,\n",
        "      custom_template_path=custom_template_path,\n",
        "      num_relax=num_relax,\n",
        "      msa_mode=msa_mode,    \n",
        "      model_type=model_type,\n",
        "      num_models=5,\n",
        "      num_recycles=num_recycles,\n",
        "      recycle_early_stop_tolerance=recycle_early_stop_tolerance,\n",
        "      num_seeds=num_seeds,\n",
        "      use_dropout=use_dropout,\n",
        "      model_order=[1,2,3,4,5],\n",
        "      is_complex=is_complex,\n",
        "      data_dir=Path(\".\"),\n",
        "      keep_existing_results=False,\n",
        "      rank_by=\"auto\",\n",
        "      pair_mode=pair_mode,\n",
        "      stop_at_score=float(100),\n",
        "      prediction_callback=prediction_callback,\n",
        "      dpi=dpi,\n",
        "      zip_results=False,\n",
        "      save_all=save_all,\n",
        "      max_msa=max_msa,\n",
        "      use_cluster_profile=use_cluster_profile,\n",
        "      input_features_callback=input_features_callback,\n",
        "      save_recycles=save_recycles,\n",
        "  )\n",
        "  results_zip = f\"{jobname}.result.zip\"\n",
        "  os.system(f\"zip -r {results_zip} {jobname}\")\n",
        "  \n",
        "  if msa_mode == \"custom\":\n",
        "    print(\"Don't forget to cite your custom MSA generation method.\")\n",
        "\n",
        "  files.download(f\"{jobname}.result.zip\")\n",
        "\n",
        "  uploaded = drive.CreateFile({'title': f\"{jobname}.result.zip\"})\n",
        "  uploaded.SetContentFile(f\"{jobname}.result.zip\")\n",
        "  uploaded.Upload()\n",
        "  print(f\"Uploaded {jobname}.result.zip to Google Drive with ID {uploaded.get('id')}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
